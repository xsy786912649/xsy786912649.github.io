<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Siliang Zeng</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Siliang Zeng</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo.jpeg" alt="" width="200px" />&nbsp;</td>
<td align="left"><p><br /> <a href="https://cse.umn.edu/ece">Electrical and Computer Engineering</a>, <br />
<a href="https://twin-cities.umn.edu/">University of Minnesota, Twin Cities</a><br />
<a href="https://scholar.google.com/citations?user=IfqsDyYAAAAJ&amp;hl=en">Google Scholar</a>, <a href="https://www.dropbox.com/scl/fi/hn3vtne77lob53bw8q8eg/Siliang-CV.pdf?rlkey=hrj5hkm3dxehulrdimsygirzv&amp;dl=0">CV</a> <br />
Email: zeng0176 <a href="at">at</a> umn (dot) edu</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a fourth year PhD student at <a href="https://twin-cities.umn.edu/">University of Minnesota</a>, advised by <a href="https://people.ece.umn.edu/~mhong/mingyi.html">Prof. Mingyi Hong</a>. <br />
Before moving to Minnesota, I received the B.S. in Statistics from <a href="https://www.cuhk.edu.cn/en">The Chinese University of Hong Kong, Shenzhen</a> in 2020. <br /></p>
<p>In my research, I am always thinking about how to design practical algorithms and systems for sequential decision making under uncertainty. <br />
My recent research interests focus on the intersection between <b>agent alignment</b>, <b>foundation models</b> and <b>reinforcement learning</b>.
<br /></p>
<h2>Experience</h2>
<ul>
<li><p>Applied Scientist Intern, Amazon Web Search (<b>AWS</b>) AI Research and Education lab, Santa Clara, May 2023 - Sep 2023. <br />
Work on finetuning large language model with reinforcement leraning. (Mentor: <a href="https://kaixianglin.github.io/">Kaixiang Lin</a>) <br /></p>
</li>
</ul>
<h2>Representative / Recent Works (* indicates equal contribution.)</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2302.07457">Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning</a> <br /> 
<b>Siliang Zeng*</b>, Chenliang Li*, Alfredo Garcia, Mingyi Hong <br />
Thirty-seventh Conference on Neural Information Processing Systems (<b>NeurIPS</b>) 2023. (<b>Oral</b>) <br /></p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2210.01282">Structural Estimation of Markov Decision Processes in High-Dimensional
State Space with Finite-Time Guarantees</a> <br /> 
<b>Siliang Zeng</b>, Mingyi Hong, Alfredo Garcia <br />
Under major revision at <b>Operations Research</b>.</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/forum?id=zbt3VmTsRIj&amp;referrer=%5Bthe%20profile%20of%20Siliang%20Zeng%5D(%2Fprofile%3Fid%3D~Siliang_Zeng1)">Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees</a> <br /> 
<b>Siliang Zeng</b>, Chenliang Li, Alfredo Garcia, Mingyi Hong <br />
Thirty-sixth Conference on Neural Information Processing Systems (<b>NeurIPS 2022</b>). <br />
(A previous version accepted by Decision Awareness in Reinforcement Learning Workshop at ICML 2022) </p>
</li>
</ul>
<h2>Recent News</h2>
<ul>
<li><p>Sep 2023: One paper has been accepted to <b>NeurIPS 2023</b> as an <b>oral</b>: <a href="https://arxiv.org/abs/2302.07457"><br /> Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning</a>. <br /></p>
</li>
</ul>
<ul>
<li><p>August 2023: One paper has been accepted to <b>Conference on Robot Learning (CoRL) 2023</b>: <a href="https://openreview.net/forum?id=W5SrUCN0yUa&amp;referrer=%5Bthe%20profile%20of%20Siliang%20Zeng%5D(%2Fprofile%3Fid%3D~Siliang_Zeng1)"><br /> A Bayesian Approach to Robust Inverse Reinforcement Learning</a>. <br /></p>
</li>
</ul>
<ul>
<li><p>May 2023: I join <b>Amazon Web Search (AWS)</b> as an applied scientist intern. I will work on reinforcement learning and large language model training.</p>
</li>
</ul>
<ul>
<li><p>March 2023: I gave an invited talk at Amazon AWS about our recent work on offline inverse reinforcement learning: <br /> 
<a href="https://arxiv.org/abs/2302.07457">Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning</a> <br /> </p>
</li>
</ul>
<ul>
<li><p>Oct 2022: I am thrilled to receive the <b>NeurIPS 2022 Scholar Award</b>. See you in New Orleans!</p>
</li>
</ul>
<ul>
<li><p>Sep 2022: Two papers have been accepted to <b>NeurIPS 2022</b>: <br />
<a href="https://openreview.net/forum?id=zbt3VmTsRIj&amp;referrer=%5Bthe%20profile%20of%20Siliang%20Zeng%5D(%2Fprofile%3Fid%3D~Siliang_Zeng1)">Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees.</a> <br />
<a href="https://openreview.net/attachment?id=0RMDK39mGg&amp;name=supplementary_material">A Stochastic Linearized Augmented Lagrangian Method for Decentralized Bilevel Optimization.</a> <br />




</p>
</li>
</ul>
<ul>
<li><p>Jul 2022: I have been selected for a travel grant from the DARL Workshop at ICML 2022! 
</p>
</li>
</ul>
<ul>
<li><p>Jun 2022: One paper has been accepted to <b>Decision Awareness in Reinforcement Learning Workshop at ICML 2022</b>: <a href="https://openreview.net/forum?id=FfELl5h3Nec"><br /> Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees</a>. <br />




</p>
</li>
</ul>
<ul>
<li><p>Jun 2022: One paper has been accepted to <b>SIAM Journal on Optimization</b>: <a href="https://arxiv.org/abs/2006.11662"><br /> On the Divergence of Decentralized Non-Convex Optimization</a>. <br />



</p>
</li>
</ul>
<ul>
<li><p>Mar 2022: One paper has been accepted to <b>L4DC 2022</b>: <a href="https://arxiv.org/abs/2110.05597"><br /> Learning to Coordinate in Multi-Agent Systems: A Coordinated Actor-Critic Algorithm and Finite-Time Guarantees</a>. <br />




</p>
</li>
</ul>
<ul>
<li><p>Sep 2021: One paper has been accepted to <b>NeurIPS 2021</b>: <a href="https://arxiv.org/abs/2102.07367"><br /> A Near-Optimal Algorithm for Stochastic Bilevel Optimization via Double-Momentum</a>. <br />


</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>

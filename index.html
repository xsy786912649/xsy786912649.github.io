<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Siyuan Xu</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Siyuan Xu</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo.jpg" alt="" width="200px" />&nbsp;</td>
<td align="left"><p><br /> School of Electrical Engineering and Computer Science, <br />
The Pennsylvania State University<br />
<a href="https://scholar.google.com/citations?user=ZV1580IAAAAJ&hl=en">Google Scholar</a> <br />
Email: spx5032@psu.edu</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a PhD student at the Pennsylvania State University, advised by <a href="https://sites.psu.edu/multiagent/">Prof. Minghui Zhu</a>. <br />
I received the B.S. in Electrical Engineering from Xi'an Jiaotong University. <br /></p>
<p>My research interests are centered around reinforcement learning, meta-learning, and LLM fine-tuning.</p>
<ul>
<li><p><b>Reinforcement Learning:</b> Algorithm design for policy optimization, meta-RL under multi-task with multi-environment, reinforcement learning from human feedback (RLHF), application to robots</p>
</li>
<li><p><b>Meta-learning:</b> Meta-reinforcement learning, pretraining on collected tasks and adapting to new tasks, human-in-the-loop adaptation, applications to robotics</p>
</li>
<li><p><b>LLM post-training:</b> Reinforcement learning for LLM fine-tuning, LLM reasoning, agentic LLM fine-tuning under complex, multi-turn interaction scenarios</p>
</li>
</ul>

<h2>Honors and Awards</h2>
<ul>
<li><p><b>Graduate Student Publication Excellence Award</b>, The Pennsylvania State University (2025)</p>
</li>
<li><p><b>Melvin P. Bloom Memorial Graduate Fellowship</b>, The Pennsylvania State University (2024)</p>
</li>
</ul>

<h2>Teaching Experiences</h2>
<ul>
<li><p><b>Teaching Assistant, EE 211/212: Circuit Analysis</b> (Spring 2024)</p>
</li>
<li><p><b>Teaching Assistant, EE 350: Continuous-Time Linear Systems</b> (Fall 2025)</p>
</li>
</ul>

<h2>Professional Services</h2>
<ul>
<li><p><b>Conference paper review:</b> ICLR; AISTATS; ICML; NeurIPS; AAAI; ICRA; IROS; ACC; CDC</p>
</li>
<li><p><b>Journal paper review:</b> IEEE TPAMI; IEEE RAL; IEEE TRO; IEEE TAC; Automatica; IEEE TCST; IEEE/CAA Journal of Automatica Sinica; IET Cyber-Systems and Robotics</p>
</li>
</ul>

<!-- 
<h2>Representative / Recent Works</h2>
<ul>
<li><p><a href="https://nips.cc/virtual/2024/poster/93412">Meta-Reinforcement Learning with Universal Policy Adaptation: Provable Near-Optimality under All-task Optimum Comparator</a> <br /> 
<b>Siyuan Xu</b>, Minghui Zhu <br />
Conference on Neural Information Processing Systems (<b>NeurIPS</b>) 2024. <br /></p>
</li>
</ul>
-->



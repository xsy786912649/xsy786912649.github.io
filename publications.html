<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>

</div></div>
<div class="infoblock">
<div class="blocktitle">Conference Papers</div>
<div class="blockcontent">

<ul>
<li><p><a href="https://openreview.net/pdf?id=ZtKXAbHQ43">Efficient Safe Meta-Reinforcement Learning: Provable Near-Optimality and Anytime Safety</a> <br /> 
<b>Siyuan Xu</b>, Minghui Zhu <br />
Neural Information Processing Systems (<b>NeurIPS 2025</b>). <br />
<br /></p>
</li>
</ul>

<ul>
<li><p><a href="https://openreview.net/pdf?id=PFMVVaPCn5">Meta-Reinforcement Learning with Human-in-the-Loop Adaptation via Preference-Order-Preserving Task Embedding</a> <br /> 
<b>Siyuan Xu</b>, Minghui Zhu <br />
International Conference on Machine Learning (<b>ICML 2025</b>). <br />
<br /></p>
</li>
</ul>

<ul>
<li><p><a href="https://openreview.net/pdf?id=rpjh69DUX2">Meta-Reinforcement Learning with Universal Policy Adaptation: Provable Near-Optimality under All-task Optimum Comparator</a> <br /> 
<b>Siyuan Xu</b>, Minghui Zhu <br />
Neural Information Processing Systems (<b>NeurIPS 2024</b>). <br />
<br /></p>
</li>
</ul>

<ul>
<li><p><a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/320e941f53db45bddc8757d1c8c4f6aa-Paper-Conference.pdf">Online Constrained Meta-Learning: Provable Guarantees for Generalization</a> <br /> 
<b>Siyuan Xu</b>, Minghui Zhu <br />
Neural Information Processing Systems (<b>NeurIPS 2023</b>), <b>Spotlight, Top 3.6%</b>. <br />
<br /></p>
</li>
</ul>

<ul>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/26473">Efficient Gradient Approximation Method for Constrained Bilevel Optimization</a> <br />
<b>Siyuan Xu</b>, Minghui Zhu <br />
AAAI Conference on Artificial Intelligence (<b>AAAI 2023</b>), <b>Oral</b>. <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://roboticsproceedings.org/rss18/p061.pdf">Meta Value Learning for Fast Policy-Centric Optimal Motion Planning</a> <br /> 
  <b>Siyuan Xu</b>, Minghui Zhu <br />
Robotics: Science and Systems (<b>RSS</b>) 2022. <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/pdf?id=k2wzVFXZmC">Explainable Reinforcement Learning from Human Feedback to Improve Large Language Model Alignment</a> <br /> 
Shicheng Liu, <b>Siyuan Xu</b>, Wenjie Qiu, Hangfan Zhang, Minghui Zhu <br />
Neural Information Processing Systems (<b>NeurIPS 2025</b>). <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://aclanthology.org/2025.emnlp-main.1085.pdf">Reinforcement Learning for Large Language Models via Group Preference Reward Shaping</a> <br /> 
Huaisheng Zhu, <b>Siyuan Xu</b>, Hangfan Zhang, Teng Xiao, Zhimeng Guo, Shijie Zhou, Shuyue Hu, Vasant G Honavar <br />
Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>, main track) 2025. <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://par.nsf.gov/servlets/purl/10488417">Federated Reinforcement Learning for Generalizable Motion Planning</a> <br /> 
Zhenyuan Yuan, <b>Siyuan Xu</b>, Minghui Zhu <br />
American Control Conference (<b>ACC</b>) 2023. <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://bpb-us-e1.wpmucdn.com/sites.psu.edu/dist/7/165391/files/2023/05/XZ-ea-ACC21.pdf">Secure Perception-Driven Control of Mobile Robots Using Chaotic Encryption</a> <br /> 
  Xu Zhang, Zhenyuan Yuan, <b>Siyuan Xu</b>, Yang Lu, Minghui Zhu <br />  
American Control Conference (<b>ACC</b>) 2023. <br />
<br /></p>
</li>
</ul>

</div>
<div class="infoblock">
<div class="blocktitle">Journal Papers</div>
<div class="blockcontent">

<ul>
<li><p><a href="https://arxiv.org/pdf/2403.13245">Federated Reinforcement Learning for Robot Motion Planning with Zero-Shot Generalization</a> <br /> 
Zhenyuan Yuan, <b>Siyuan Xu</b>, Minghui Zhu <br />
Automatica, 2024. <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10241989">Secure Perception-Driven Control of Mobile Robots Using Chaotic Encryption</a> <br /> 
Xu Zhang, Zhenyuan Yuan, <b>Siyuan Xu</b>, Yang Lu, Minghui Zhu <br />  
IEEE Transactions on Automatic Control, 2023. <br />
<br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10994-025-06810-4">All-time Safety and Sample-efficient Meta Update for Online Safe Meta Reinforcement Learning under Markov Task Transition</a> <br /> 
Zhenyuan Yuan, <b>Siyuan Xu</b>, Minghui Zhu <br />
Machine Learning, 2025. <br />
<br /></p>
</li>
</ul>


</div></div>
</td>
</tr>
</table>
</body>
</html>

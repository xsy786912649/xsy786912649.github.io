% https://www.overleaf.com/latex/templates/cis-grad-template-dev/pjcttwysqvym
\documentclass{resume} % Use the custom resume.cls style

\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{comment}
\usepackage[left=0.4 in,top=0.4in,right=0.4 in,bottom=0.4in]{geometry} 
\usepackage{hyperref}
\usepackage{graphicx}

\newcommand{\pdflink}[1]{%
  \href{#1}{\raisebox{-0.8ex}{\includegraphics[height=3ex]{paper.png}}}%
}

% Define new counters
\newcounter{Ccounter}
\newcounter{Pcounter}
\newcounter{Jcounter}

% Define commands to use the custom labels and increment the counters
\newcommand{\clabel}{[C\arabic{Ccounter}]}
\newcommand{\plabel}{[P\arabic{Pcounter}]}
\newcommand{\jlabel}{[J\arabic{Jcounter}]}
\newcommand{\citem}{\stepcounter{Ccounter}\item[\clabel]}
\newcommand{\pitem}{\stepcounter{Pcounter}\item[\plabel]}
\newcommand{\jitem}{\stepcounter{Jcounter}\item[\jlabel]}

\newcommand{\tab}[1]{\hspace{.2667\textwidth}\rlap{#1}} 
\hypersetup{colorlinks=true, linkcolor=black, filecolor=black, citecolor=black, urlcolor=black}
\definecolor{darkblue}{rgb}{0.0, 0.0, 0.55}
\setuldepth{Mo}
\newcommand{\me}{\textbf{Siyuan Xu}}
\newcommand{\iclr}[1]{International Conference on Learning Representations (ICLR), #1}
\newcommand{\icml}[1]{International Conference on Machine Learning (ICML), #1}
\newcommand{\neurips}[1]{Annual Conference on Neural Information Processing Systems (NeurIPS), #1}
\newcommand{\aaai}[1]{AAAI Conference on Artificial Intelligence (AAAI), #1}
\newcommand{\cikm}[1]{International Conference on Information and Knowledge Management (CIKM), #1}
\newcommand{\logc}[1]{Learning on Graphs Conference (LoG), #1}

\newcommand{\highlight}[1]{{\bf #1}}
\newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}

\name{Siyuan Xu}
\address{\href{mailto:spx5032@psu.edu}{\color{darkblue}spx5032@psu.edu} \\ \href{https://xsy786912649.github.io}{\color{darkblue}Homepage} \\ \href{https://scholar.google.com/citations?user=ZV1580IAAAAJ&hl=en}{\color{darkblue}Google Scholar}}  %


\begin{document}

\begin{rSection}{Education}
\vspace{0.4em}
\begin{itemize}[topsep=2pt,itemsep=2pt,leftmargin=0.15in]
\item {\bf The Pennsylvania State University} \hfill {State College, PA} \\
\emph{Ph.D., Electrical Engineering and Computer Science} \hfill {\emph{Aug 2020 -- Present}}
\begin{itemize}[topsep=-0pt,itemsep=-3pt,leftmargin=0.3in]
\item {\bf Ph.D. dissertation}: Meta-learning for Fast and Safe Adaptation in Autonomous Systems 
\item {\bf Advisor}: Prof. Minghui Zhu
\end{itemize}
\item {\bf Xi'an Jiaotong University} \hfill {Xi'an, Shaanxi} \\ 
\emph{B.E., Electrical Engineering} \hfill {\emph{Sep 2015 -- Jun 2019}}
\begin{itemize}[topsep=-0pt,itemsep=-3pt,leftmargin=0.3in]
\item {\bf B.E. dissertation}: Knowledge Extraction and Intelligent QA for Power System Operation Logs 
\item {\bf Advisor}: Prof. Hui Cao
\end{itemize}
\end{itemize}
\end{rSection}

\begin{rSection}{Research Interests}
\vspace{0.4em}
My research interests are centered around optimization, reinforcement learning, meta-learning, and LLM fine-tuning.
\begin{itemize}[topsep=-0.0pt,itemsep=-0.0pt,leftmargin=0.3in]
\item \textbf{Reinforcement Learning:} Algorithm design for policy optimization, meta-RL under multi-task with multi-environment, reinforcement learning from human feedback (RLHF), application to robots
\item \textbf{Meta-learning:} Meta-reinforcement learning, pretraining on collected tasks and adapting to new tasks, human-in-the-loop adaptation, applications to robotics.
\item \textbf{LLM post-training:} Reinforcement learning for LLM fine-tuning, LLM reasoning, agentic LLM fine-tuning under complex, multi-turn interaction scenarios.
\end{itemize}
\end{rSection}

\begin{rSection}{Research Experiences}
\vspace{0.4em}
\begin{itemize}[topsep=2pt,itemsep=2pt,leftmargin=0.15in]

\item {\bf Multi-agent Networks Laboratory}, The Pennsylvania State University  \hfill {State College, PA} \\
\emph{Graduate Research Assistant} \hfill {\emph{Aug 2020 -- Present}} \\
{\bf Advisor}: Prof. Minghui Zhu
\begin{itemize}[topsep=0pt,itemsep=0pt,leftmargin=0.3in]
\item {\bf Meta-reinforcement learning algorithm and theory}: Developed a series of provably efficient meta-RL algorithms for fast adaptation across tasks and environments, including universal policy adaptation, preference-order-preserving task embeddings, and anytime-safe policy updates. [C1], [C2], [C3], [C4], [C6], [J3], [P7] 
\item {\bf Bilevel optimization algorithm and theory}: Studied constrained bilevel optimization problems arising in meta-learning and control. Proposed efficient gradient approximation methods with theoretical convergence guarantees. [C4], [C5]
\item {\bf Secure and safe learning in robot system}: Developed safety-aware reinforcement learning and meta-learning algorithms with all-time safety guarantees, enabling reliable deployment in safety-critical robotic motion planning and control tasks. [C6], [C9], [C10], [J1], [J2], [P7]
\item {\bf LLM post-training}: Investigated reinforcement learning methods for large language model post-training, including preference optimization and explainable reinforcement learning from human feedback. [C7], [P2]
\item {\bf RL for cyber-security}: 
Designed scalable reinforcement learning frameworks for proactive defense against lateral movement attacks under delayed and inaccurate monitoring. [P3], [P4] 
\end{itemize}

\item {\bf Amazon, Rufus} \hfill {Palo Alto, CA} \\
\emph{Applied Scientist Intern} \hfill {\emph{May 2025 -- Dec 2025}} \\
{\bf Mentor}: Dr. Shiyang Li
\begin{itemize}[topsep=0pt,itemsep=2pt,leftmargin=0.3in]
\item {\bf LLM post-training for tool use}:  
Developed a reinforcement learning pipeline for improving general tool-calling in large language models via verifiable multi-turn data synthesis with oracle-preserved rewards. [P1]
\end{itemize}

\item {\bf The Chinese University of Hong Kong} \hfill {Hong Kong} \\
\emph{Research Assistant} \hfill {\emph{Feb 2020 -- Aug 2020}} \\
{\bf Advisor}: Prof. Darwin Lau
\begin{itemize}[topsep=0pt,itemsep=0pt,leftmargin=0.3in]
\item {\bf Computer vision and robotics systems}:  
Developed a computer vision pipeline for camera–robot calibration and real-time localization in cable-driven parallel robots, integrating perception with system modeling for accurate state estimation and experimental validation.
\end{itemize}

\item {\bf Xi'an Jiaotong University} \hfill {Xi'an, Shaanxi} \\
\emph{Undergraduate Research Assistant} \hfill {\emph{Sep 2016 -- Jun 2019}} \\
{\bf Advisor}: Prof. Hui Cao
\begin{itemize}[topsep=-0pt,itemsep=-0pt,leftmargin=0.3in]
\item {\bf Robotics systems}: 
Focused on robot control, embedded systems, and system-level integration using ROS for wheeled robots. Implemented control and perception pipelines on physical wheeled robotic platforms with real-time sensing and actuation. 
\end{itemize}

\end{itemize}
\end{rSection}



\begin{rSection}{Publications}
\vspace{0.3em} 
{\bf Summary} \par\vspace{-0.15em}\noindent
Reinforcement learning: [C1], [C2], [C3], [C7], [C8], [C9], [J1], [J3], [P3], [P4]; Meta-learning: [C1], [C2], [C3], [C4], [C5], [P2], [J3]; Robotics: [C6], [C9], [C10], [J1], [J2], [P7]; Optimization [C4], [C5]; LLM post-training: [P1], [P2], [P5], [P6], [C7], [C8].

{\bf Conference Papers}
\begin{enumerate}[label={}]
\citem {Efficient Safe Meta-Reinforcement Learning: Provable Near-Optimality and Anytime Safety \pdflink{https://openreview.net/pdf?id=ZtKXAbHQ43}}\\
\me, Minghui Zhu \\
\neurips{2025}.

\citem {Meta-Reinforcement Learning with Human-in-the-Loop Adaptation via Preference-Order-Preserving Task Embedding
\pdflink{https://openreview.net/pdf?id=PFMVVaPCn5}
}\\
\me, Minghui Zhu \\
\icml{2025}.

\citem
{Meta-Reinforcement Learning with Universal Policy Adaptation: Provable Near-Optimality under All-task Optimum Comparator
\pdflink{https://openreview.net/pdf?id=rpjh69DUX2}
}\\
\me, Minghui Zhu \\
\neurips{2024}.

\citem 
{Online Constrained Meta-Learning: Provable Guarantees for Generalization
\pdflink{https://proceedings.neurips.cc/paper_files/paper/2023/file/320e941f53db45bddc8757d1c8c4f6aa-Paper-Conference.pdf}
}\\
\me, Minghui Zhu \\
\neurips{2023}, {\bf Spotlight (Top 3.6\%)}

\citem
{Efficient Gradient Approximation Method for Constrained Bilevel Optimization
\pdflink{https://ojs.aaai.org/index.php/AAAI/article/view/26473}
}\\
\me, Minghui Zhu \\
\aaai{2023}, {\bf Oral}

\citem {Meta Value Learning for Fast Policy-Centric Optimal Motion Planning
\pdflink{https://roboticsproceedings.org/rss18/p061.pdf}
}\\
\me, Minghui Zhu \\
Robotics: Science and Systems (RSS), 2022.

\citem {Explainable Reinforcement Learning from Human Feedback to Improve Large Language Model Alignment
\pdflink{https://openreview.net/pdf?id=k2wzVFXZmC}
}\\
Shicheng Liu, \me, Wenjie Qiu, Hangfan Zhang, Minghui Zhu \\
\neurips{2025}.

\citem {Reinforcement Learning for Large Language Models via Group Preference Reward Shaping
\pdflink{https://aclanthology.org/2025.emnlp-main.1085.pdf}
} \\
Huaisheng Zhu, \me, Hangfan Zhang, Teng Xiao, Zhimeng Guo, Shijie Zhou, Shuyue Hu, Vasant G Honavar \\
Conference on Empirical Methods in Natural Language Processing (EMNLP, main track), 2025.

\citem {Federated Reinforcement Learning for Generalizable Motion Planning
\pdflink{https://par.nsf.gov/servlets/purl/10488417}
}\\
Zhenyuan Yuan, \me, Minghui Zhu \\
American Control Conference (ACC), 2023.

\citem {Secure Perception-Driven Control of Mobile Robots Using Chaotic Encryption
\pdflink{https://bpb-us-e1.wpmucdn.com/sites.psu.edu/dist/7/165391/files/2023/05/XZ-ea-ACC21.pdf}
}\\
Xu Zhang, Zhenyuan Yuan, \me, Yang Lu, Minghui Zhu
\\
American Control Conference (ACC), 2023.
\end{enumerate}

{\bf Journal Papers}
\begin{enumerate}[label={}]
\jitem {Federated reinforcement learning for robot motion planning with zero-shot generalization
\pdflink{https://arxiv.org/pdf/2403.13245}
} \\
Zhenyuan Yuan, \me, Minghui Zhu \\
Automatica, 2024.

\jitem {Secure Perception-Driven Control of Mobile Robots Using Chaotic Encryption
\pdflink{https://ieeexplore.ieee.org/document/10241989}
}\\
Xu Zhang, Zhenyuan Yuan, \me, Yang Lu, Minghui Zhu \\
IEEE Transactions on Automatic Control, 2023.

\jitem {All-time Safety and Sample-efficient Meta Update for Online Safe Meta Reinforcement Learning under Markov Task Transition
\pdflink{https://link.springer.com/article/10.1007/s10994-025-06810-4}
}\\
Zhenyuan Yuan, \me, Minghui Zhu \\
Machine Learning, 2025.
\end{enumerate}

{\bf Submitted Papers}
\begin{enumerate}[label={}]
\pitem {Verifiable Mock Tool-Calling Data Synthesis for Reinforcement Learning: Controllable Improvement of Tool Use in Large Language Models}\\
\me, Xin Liu, Shiyang Li \\
Submitted.

\pitem {Iterative Preference Optimization with Proximal Policy Regularization for Large Language Model Alignment}\\
\me, Hangfan Zhang, Zhimeng Guo, Huaisheng Zhu, Yue Mao, Shicheng Liu, Minghui Zhu \\
Submitted.

\pitem {Scalable Reinforcement Learning for Proactive
Defense Against Lateral Movement Attacks}\\
\me, Lan Zhang, Pei-Yu Tseng, Fan Zhang, Minghui Zhu, Peng Liu\\
Submitted.

\pitem {Dual-Source State Estimation for Reinforcement
Learning Defense against Lateral Movement
Attacks under Delayed and Inaccurate Monitoring}\\
\me, Pei-Yu Tseng, Lan Zhang, Minghui Zhu, Peng Liu\\
Submitted.

\pitem {The Path of Self-Evolving Large Language Models: Achieving Data-Efficient Learning via Intrinsic Feedback} \\
Hangfan Zhang, \me, Zhimeng Guo, Huaisheng Zhu, Shicheng Liu, Xinrun Wang, Qiaosheng Zhang, Yang Chen, Peng Ye, Lei Bai, Shuyue Hu \\
Submitted.

\pitem {Optimizing Token Choice for Code Watermarking: An RL Approach} \\
Zhimeng Guo, Huaisheng Zhu, \me, Hangfan Zhang, Teng Xiao, Minhao Cheng \\
Submitted

\pitem {Fast Policy-Centric Optimal Motion Planning via Control-Informed Meta-Learning} \\
\me, Yue Mao, Minghui Zhu \\
Submitted

\end{enumerate}
\end{rSection}

\begin{rSection}{Honors and Awards}
\vspace{0.4em}
\begin{itemize}[topsep=0.0pt,itemsep=-1.5pt,leftmargin=0.15in]

\item \textbf{Graduate Student Publication Excellence Award} \hfill {2025} \\
\emph{The Pennsylvania State University}

\item \textbf{Melvin P. Bloom Memorial Graduate Fellowship} \hfill {2024} \\
\emph{The Pennsylvania State University}

\item \textbf{Outstanding Student Scholarship}
\hfill {2016 - 2019} \\
\emph{Xi’an Jiaotong University}
\end{itemize}
\end{rSection}


\begin{rSection}{Grant Proposal Writing Experiences}
\vspace{0.4em}
\begin{itemize}[topsep=0.0pt,itemsep=0.0pt,leftmargin=0.15in]

\item \textbf{An Innovative RL Tool Suite Integrating Physics-Based Environments for Real-Time DER Systems} \\
U.S. Department of Energy (DOE), \$3.75M  \hfill {Oct.\ 2023} 

\item \textbf{Towards Scalable and Strengthened Protection of Mobile Health Data via Trusted Execution Environments}\\
U.S. National Institutes of Health (NIH), \$1.2M  \hfill {Sep.\ 2025} 

\end{itemize}
\end{rSection}

\begin{rSection}{Teaching Experiences}
\vspace{0.4em}

\begin{itemize}[topsep=0pt,itemsep=0pt,leftmargin=0.15in]

\item \textbf{ENGR 888: Seminar for Engineering Teaching Assistants}
\begin{itemize}[topsep=-2pt,itemsep=0pt,leftmargin=0.2in]
\item Completed formal pedagogical training; earned grade A.
\end{itemize}

\item \textbf{Teaching Assistant, EE 211/212: Circuit Analysis} \hfill \textit{Spring 2024}
\begin{itemize}[topsep=-2pt,itemsep=0pt,leftmargin=0.2in]
\item Conducted one weekly recitation; graded homework and examinations.
\end{itemize}

\item \textbf{Teaching Assistant, EE 350: Continuous-Time Linear Systems} \hfill \textit{Fall 2025}
\begin{itemize}[topsep=-2pt,itemsep=0pt,leftmargin=0.2in]
\item Conducted two weekly recitations; graded homework and exams; prepared exam questions.
\end{itemize}

\item \textbf{Research Mentorship}
\begin{itemize}[topsep=-2pt,itemsep=0pt,leftmargin=0.2in]
\item Mentored two junior Ph.D. and M.S. students, Yue Mao and Monther Al Siyabi, resulted in publications [P7].
\end{itemize}

\end{itemize}
\end{rSection}

\begin{rSection}{Presentations}
\vspace{0.4em}

\begin{itemize}[topsep=0pt,itemsep=0pt,leftmargin=0.15in]

\item \textbf{Efficient Safe Meta-Reinforcement Learning} \hfill \textit{December 2025}\\
\emph{Annual Conference on Neural Information Processing Systems (NeurIPS), San Diego, CA}

\item \textbf{Meta-Reinforcement Learning with Human-in-the-Loop Adaptation} \hfill \textit{2025}\\
\emph{Institute of Networking and Security Research (INSR) Industry Day, Pennsylvania State University}

\item \textbf{Meta-Reinforcement Learning with Universal Policy Adaptation} \hfill \textit{December 2024}\\
\emph{Annual Conference on Neural Information Processing Systems (NeurIPS), New Orleans, LA}

\item \textbf{Meta-Reinforcement Learning with Universal Policy Adaptation} \hfill \textit{2024}\\
\emph{Institute of Networking and Security Research (INSR) Industry Day, Pennsylvania State University} \\
\emph{Institute for Computational and Data Sciences (ICDS) Symposium, Pennsylvania State University}

\item \textbf{Online Constrained Meta-Learning: Provable Guarantees for Generalization} \hfill \textit{December 2023}\\
\emph{Annual Conference on Neural Information Processing Systems (NeurIPS), New Orleans, LA}

\item \textbf{Efficient Gradient Approximation Method for Constrained Bilevel Optimization} \hfill \textit{February 2023}\\
\emph{AAAI Conference on Artificial Intelligence (AAAI), Washington, DC}

\item \textbf{Meta Value Learning for Fast Policy-Centric Optimal Motion Planning} \hfill \textit{June 2022}\\
\emph{Robotics: Science and Systems (RSS), New York City, NY}

\end{itemize}

\end{rSection}

\begin{rSection}{Professional Services}
\vspace{0.6em}
\begin{itemize}[topsep=3.0pt,itemsep=0.0pt,leftmargin=0.15in]
\item \textbf{Journal paper review}
\begin{itemize}[topsep=0.0pt,itemsep=-3.0pt,leftmargin=0.3in]
\item IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI)
\item IEEE Robotics and Automation Letters (IEEE RAL)
\item IEEE Transactions on Robotics (IEEE TRO)
\item IEEE Transactions on Automatic Control (IEEE TAC)
\item Automatica
\item IEEE Transactions on Control Systems and Technology (IEEE TCST)
\item IEEE/CAA Journal of Automatica Sinica
\item IET Cyber-Systems and Robotics
\end{itemize}

\item \textbf{Conference paper review}
\begin{itemize}[topsep=0.0pt,itemsep=-3.0pt,leftmargin=0.3in]
\item International Conference on Learning Representations (ICLR)
\item International Conference on Artificial Intelligence and Statistics (AISTATS)
\item International Conference on Machine Learning (ICML)
\item Annual Conference on Neural Information Processing Systems (NeurIPS)
\item AAAI Conference on Artificial Intelligence (AAAI)
\item IEEE International Conference on Robotics and Automation (ICRA)
\item IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
\item IEEE American Control Conference (ACC)
\item IEEE Conference on Decision and Control (CDC) 
\end{itemize}
\end{itemize}
\end{rSection}

\end{document}
